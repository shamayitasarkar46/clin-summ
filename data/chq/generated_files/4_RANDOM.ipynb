{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating 4 RANDOM samples & creating 150 txt files** #"
      ],
      "metadata": {
        "id": "Kz2VoycjfAQ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrzun7KDe2XK",
        "outputId": "57cb58da-a79b-4e8e-8e0c-84a5ccba5f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "#from sklearn.metrics.pairwise import euclidean_distances\n",
        "import random\n",
        "\n",
        "# Load the model\n",
        "model = SentenceTransformer(\"pritamdeka/PubMedBERT-mnli-snli-scinli-scitail-mednli-stsb\")\n"
      ],
      "metadata": {
        "id": "KXf0J7MSe8Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def create_samples(test_data, train_data, output_dir, num_samples=4):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    train_texts = [entry['inputs'] for entry in train_data]\n",
        "    train_encodings = model.encode(train_texts, convert_to_tensor=True).detach().cpu().numpy()\n",
        "\n",
        "    for idx, test_entry in enumerate(test_data):\n",
        "        # similar_entries = find_similar_entries(test_entry, train_encodings, train_data, num_samples)\n",
        "        random_samples = random.sample(train_data, min(num_samples, len(train_data)))\n",
        "        output_file = os.path.join(output_dir, f'random_samples_{idx+1}.txt')\n",
        "        with open(output_file, 'w', encoding='utf-8') as file:\n",
        "            # Write test entry as JSON object on its own line without indentation\n",
        "            file.write(json.dumps({\"type\": \"TEST_ENTRY\", \"data\": test_entry}) + '\\n')\n",
        "            # Write similar train entries as JSON objects on their own lines without indentation\n",
        "            for entry in random_samples:\n",
        "                file.write(json.dumps({\"type\": \"TRAIN_ENTRY\", \"data\": entry}) + '\\n')\n",
        "        print(f\"Random samples for test + train entry {idx+1} have been saved to '{output_file}'\")\n",
        "\n",
        "def load_jsonl(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        return [json.loads(line) for line in f]\n",
        "\n",
        "# Define file paths\n",
        "output_dir = '4_output_samples'\n",
        "\n",
        "folder_name = '/data/chq'\n",
        "train_file_name = 'train.jsonl'\n",
        "test_file_name = 'test.jsonl'\n",
        "\n",
        "# Join the folder and file names to create a full path\n",
        "train_file = os.path.join(folder_name, train_file_name)\n",
        "test_file = os.path.join(folder_name, test_file_name)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load train and test data\n",
        "    train_data = load_jsonl(train_file)\n",
        "    test_data = load_jsonl(test_file)\n",
        "\n",
        "    # Create and save similar samples\n",
        "    create_samples(test_data, train_data, output_dir)\n",
        "    print(f\"Random samples have been saved to '{output_dir}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrXyeYpofIQI",
        "outputId": "62ed1838-b684-4d3a-b8cc-0bb32a6e5a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random samples for test + train entry 1 have been saved to '4_output_samples/random_samples_1.txt'\n",
            "Random samples for test + train entry 2 have been saved to '4_output_samples/random_samples_2.txt'\n",
            "Random samples for test + train entry 3 have been saved to '4_output_samples/random_samples_3.txt'\n",
            "Random samples for test + train entry 4 have been saved to '4_output_samples/random_samples_4.txt'\n",
            "Random samples for test + train entry 5 have been saved to '4_output_samples/random_samples_5.txt'\n",
            "Random samples for test + train entry 6 have been saved to '4_output_samples/random_samples_6.txt'\n",
            "Random samples for test + train entry 7 have been saved to '4_output_samples/random_samples_7.txt'\n",
            "Random samples for test + train entry 8 have been saved to '4_output_samples/random_samples_8.txt'\n",
            "Random samples for test + train entry 9 have been saved to '4_output_samples/random_samples_9.txt'\n",
            "Random samples for test + train entry 10 have been saved to '4_output_samples/random_samples_10.txt'\n",
            "Random samples for test + train entry 11 have been saved to '4_output_samples/random_samples_11.txt'\n",
            "Random samples for test + train entry 12 have been saved to '4_output_samples/random_samples_12.txt'\n",
            "Random samples for test + train entry 13 have been saved to '4_output_samples/random_samples_13.txt'\n",
            "Random samples for test + train entry 14 have been saved to '4_output_samples/random_samples_14.txt'\n",
            "Random samples for test + train entry 15 have been saved to '4_output_samples/random_samples_15.txt'\n",
            "Random samples for test + train entry 16 have been saved to '4_output_samples/random_samples_16.txt'\n",
            "Random samples for test + train entry 17 have been saved to '4_output_samples/random_samples_17.txt'\n",
            "Random samples for test + train entry 18 have been saved to '4_output_samples/random_samples_18.txt'\n",
            "Random samples for test + train entry 19 have been saved to '4_output_samples/random_samples_19.txt'\n",
            "Random samples for test + train entry 20 have been saved to '4_output_samples/random_samples_20.txt'\n",
            "Random samples for test + train entry 21 have been saved to '4_output_samples/random_samples_21.txt'\n",
            "Random samples for test + train entry 22 have been saved to '4_output_samples/random_samples_22.txt'\n",
            "Random samples for test + train entry 23 have been saved to '4_output_samples/random_samples_23.txt'\n",
            "Random samples for test + train entry 24 have been saved to '4_output_samples/random_samples_24.txt'\n",
            "Random samples for test + train entry 25 have been saved to '4_output_samples/random_samples_25.txt'\n",
            "Random samples for test + train entry 26 have been saved to '4_output_samples/random_samples_26.txt'\n",
            "Random samples for test + train entry 27 have been saved to '4_output_samples/random_samples_27.txt'\n",
            "Random samples for test + train entry 28 have been saved to '4_output_samples/random_samples_28.txt'\n",
            "Random samples for test + train entry 29 have been saved to '4_output_samples/random_samples_29.txt'\n",
            "Random samples for test + train entry 30 have been saved to '4_output_samples/random_samples_30.txt'\n",
            "Random samples for test + train entry 31 have been saved to '4_output_samples/random_samples_31.txt'\n",
            "Random samples for test + train entry 32 have been saved to '4_output_samples/random_samples_32.txt'\n",
            "Random samples for test + train entry 33 have been saved to '4_output_samples/random_samples_33.txt'\n",
            "Random samples for test + train entry 34 have been saved to '4_output_samples/random_samples_34.txt'\n",
            "Random samples for test + train entry 35 have been saved to '4_output_samples/random_samples_35.txt'\n",
            "Random samples for test + train entry 36 have been saved to '4_output_samples/random_samples_36.txt'\n",
            "Random samples for test + train entry 37 have been saved to '4_output_samples/random_samples_37.txt'\n",
            "Random samples for test + train entry 38 have been saved to '4_output_samples/random_samples_38.txt'\n",
            "Random samples for test + train entry 39 have been saved to '4_output_samples/random_samples_39.txt'\n",
            "Random samples for test + train entry 40 have been saved to '4_output_samples/random_samples_40.txt'\n",
            "Random samples for test + train entry 41 have been saved to '4_output_samples/random_samples_41.txt'\n",
            "Random samples for test + train entry 42 have been saved to '4_output_samples/random_samples_42.txt'\n",
            "Random samples for test + train entry 43 have been saved to '4_output_samples/random_samples_43.txt'\n",
            "Random samples for test + train entry 44 have been saved to '4_output_samples/random_samples_44.txt'\n",
            "Random samples for test + train entry 45 have been saved to '4_output_samples/random_samples_45.txt'\n",
            "Random samples for test + train entry 46 have been saved to '4_output_samples/random_samples_46.txt'\n",
            "Random samples for test + train entry 47 have been saved to '4_output_samples/random_samples_47.txt'\n",
            "Random samples for test + train entry 48 have been saved to '4_output_samples/random_samples_48.txt'\n",
            "Random samples for test + train entry 49 have been saved to '4_output_samples/random_samples_49.txt'\n",
            "Random samples for test + train entry 50 have been saved to '4_output_samples/random_samples_50.txt'\n",
            "Random samples for test + train entry 51 have been saved to '4_output_samples/random_samples_51.txt'\n",
            "Random samples for test + train entry 52 have been saved to '4_output_samples/random_samples_52.txt'\n",
            "Random samples for test + train entry 53 have been saved to '4_output_samples/random_samples_53.txt'\n",
            "Random samples for test + train entry 54 have been saved to '4_output_samples/random_samples_54.txt'\n",
            "Random samples for test + train entry 55 have been saved to '4_output_samples/random_samples_55.txt'\n",
            "Random samples for test + train entry 56 have been saved to '4_output_samples/random_samples_56.txt'\n",
            "Random samples for test + train entry 57 have been saved to '4_output_samples/random_samples_57.txt'\n",
            "Random samples for test + train entry 58 have been saved to '4_output_samples/random_samples_58.txt'\n",
            "Random samples for test + train entry 59 have been saved to '4_output_samples/random_samples_59.txt'\n",
            "Random samples for test + train entry 60 have been saved to '4_output_samples/random_samples_60.txt'\n",
            "Random samples for test + train entry 61 have been saved to '4_output_samples/random_samples_61.txt'\n",
            "Random samples for test + train entry 62 have been saved to '4_output_samples/random_samples_62.txt'\n",
            "Random samples for test + train entry 63 have been saved to '4_output_samples/random_samples_63.txt'\n",
            "Random samples for test + train entry 64 have been saved to '4_output_samples/random_samples_64.txt'\n",
            "Random samples for test + train entry 65 have been saved to '4_output_samples/random_samples_65.txt'\n",
            "Random samples for test + train entry 66 have been saved to '4_output_samples/random_samples_66.txt'\n",
            "Random samples for test + train entry 67 have been saved to '4_output_samples/random_samples_67.txt'\n",
            "Random samples for test + train entry 68 have been saved to '4_output_samples/random_samples_68.txt'\n",
            "Random samples for test + train entry 69 have been saved to '4_output_samples/random_samples_69.txt'\n",
            "Random samples for test + train entry 70 have been saved to '4_output_samples/random_samples_70.txt'\n",
            "Random samples for test + train entry 71 have been saved to '4_output_samples/random_samples_71.txt'\n",
            "Random samples for test + train entry 72 have been saved to '4_output_samples/random_samples_72.txt'\n",
            "Random samples for test + train entry 73 have been saved to '4_output_samples/random_samples_73.txt'\n",
            "Random samples for test + train entry 74 have been saved to '4_output_samples/random_samples_74.txt'\n",
            "Random samples for test + train entry 75 have been saved to '4_output_samples/random_samples_75.txt'\n",
            "Random samples for test + train entry 76 have been saved to '4_output_samples/random_samples_76.txt'\n",
            "Random samples for test + train entry 77 have been saved to '4_output_samples/random_samples_77.txt'\n",
            "Random samples for test + train entry 78 have been saved to '4_output_samples/random_samples_78.txt'\n",
            "Random samples for test + train entry 79 have been saved to '4_output_samples/random_samples_79.txt'\n",
            "Random samples for test + train entry 80 have been saved to '4_output_samples/random_samples_80.txt'\n",
            "Random samples for test + train entry 81 have been saved to '4_output_samples/random_samples_81.txt'\n",
            "Random samples for test + train entry 82 have been saved to '4_output_samples/random_samples_82.txt'\n",
            "Random samples for test + train entry 83 have been saved to '4_output_samples/random_samples_83.txt'\n",
            "Random samples for test + train entry 84 have been saved to '4_output_samples/random_samples_84.txt'\n",
            "Random samples for test + train entry 85 have been saved to '4_output_samples/random_samples_85.txt'\n",
            "Random samples for test + train entry 86 have been saved to '4_output_samples/random_samples_86.txt'\n",
            "Random samples for test + train entry 87 have been saved to '4_output_samples/random_samples_87.txt'\n",
            "Random samples for test + train entry 88 have been saved to '4_output_samples/random_samples_88.txt'\n",
            "Random samples for test + train entry 89 have been saved to '4_output_samples/random_samples_89.txt'\n",
            "Random samples for test + train entry 90 have been saved to '4_output_samples/random_samples_90.txt'\n",
            "Random samples for test + train entry 91 have been saved to '4_output_samples/random_samples_91.txt'\n",
            "Random samples for test + train entry 92 have been saved to '4_output_samples/random_samples_92.txt'\n",
            "Random samples for test + train entry 93 have been saved to '4_output_samples/random_samples_93.txt'\n",
            "Random samples for test + train entry 94 have been saved to '4_output_samples/random_samples_94.txt'\n",
            "Random samples for test + train entry 95 have been saved to '4_output_samples/random_samples_95.txt'\n",
            "Random samples for test + train entry 96 have been saved to '4_output_samples/random_samples_96.txt'\n",
            "Random samples for test + train entry 97 have been saved to '4_output_samples/random_samples_97.txt'\n",
            "Random samples for test + train entry 98 have been saved to '4_output_samples/random_samples_98.txt'\n",
            "Random samples for test + train entry 99 have been saved to '4_output_samples/random_samples_99.txt'\n",
            "Random samples for test + train entry 100 have been saved to '4_output_samples/random_samples_100.txt'\n",
            "Random samples for test + train entry 101 have been saved to '4_output_samples/random_samples_101.txt'\n",
            "Random samples for test + train entry 102 have been saved to '4_output_samples/random_samples_102.txt'\n",
            "Random samples for test + train entry 103 have been saved to '4_output_samples/random_samples_103.txt'\n",
            "Random samples for test + train entry 104 have been saved to '4_output_samples/random_samples_104.txt'\n",
            "Random samples for test + train entry 105 have been saved to '4_output_samples/random_samples_105.txt'\n",
            "Random samples for test + train entry 106 have been saved to '4_output_samples/random_samples_106.txt'\n",
            "Random samples for test + train entry 107 have been saved to '4_output_samples/random_samples_107.txt'\n",
            "Random samples for test + train entry 108 have been saved to '4_output_samples/random_samples_108.txt'\n",
            "Random samples for test + train entry 109 have been saved to '4_output_samples/random_samples_109.txt'\n",
            "Random samples for test + train entry 110 have been saved to '4_output_samples/random_samples_110.txt'\n",
            "Random samples for test + train entry 111 have been saved to '4_output_samples/random_samples_111.txt'\n",
            "Random samples for test + train entry 112 have been saved to '4_output_samples/random_samples_112.txt'\n",
            "Random samples for test + train entry 113 have been saved to '4_output_samples/random_samples_113.txt'\n",
            "Random samples for test + train entry 114 have been saved to '4_output_samples/random_samples_114.txt'\n",
            "Random samples for test + train entry 115 have been saved to '4_output_samples/random_samples_115.txt'\n",
            "Random samples for test + train entry 116 have been saved to '4_output_samples/random_samples_116.txt'\n",
            "Random samples for test + train entry 117 have been saved to '4_output_samples/random_samples_117.txt'\n",
            "Random samples for test + train entry 118 have been saved to '4_output_samples/random_samples_118.txt'\n",
            "Random samples for test + train entry 119 have been saved to '4_output_samples/random_samples_119.txt'\n",
            "Random samples for test + train entry 120 have been saved to '4_output_samples/random_samples_120.txt'\n",
            "Random samples for test + train entry 121 have been saved to '4_output_samples/random_samples_121.txt'\n",
            "Random samples for test + train entry 122 have been saved to '4_output_samples/random_samples_122.txt'\n",
            "Random samples for test + train entry 123 have been saved to '4_output_samples/random_samples_123.txt'\n",
            "Random samples for test + train entry 124 have been saved to '4_output_samples/random_samples_124.txt'\n",
            "Random samples for test + train entry 125 have been saved to '4_output_samples/random_samples_125.txt'\n",
            "Random samples for test + train entry 126 have been saved to '4_output_samples/random_samples_126.txt'\n",
            "Random samples for test + train entry 127 have been saved to '4_output_samples/random_samples_127.txt'\n",
            "Random samples for test + train entry 128 have been saved to '4_output_samples/random_samples_128.txt'\n",
            "Random samples for test + train entry 129 have been saved to '4_output_samples/random_samples_129.txt'\n",
            "Random samples for test + train entry 130 have been saved to '4_output_samples/random_samples_130.txt'\n",
            "Random samples for test + train entry 131 have been saved to '4_output_samples/random_samples_131.txt'\n",
            "Random samples for test + train entry 132 have been saved to '4_output_samples/random_samples_132.txt'\n",
            "Random samples for test + train entry 133 have been saved to '4_output_samples/random_samples_133.txt'\n",
            "Random samples for test + train entry 134 have been saved to '4_output_samples/random_samples_134.txt'\n",
            "Random samples for test + train entry 135 have been saved to '4_output_samples/random_samples_135.txt'\n",
            "Random samples for test + train entry 136 have been saved to '4_output_samples/random_samples_136.txt'\n",
            "Random samples for test + train entry 137 have been saved to '4_output_samples/random_samples_137.txt'\n",
            "Random samples for test + train entry 138 have been saved to '4_output_samples/random_samples_138.txt'\n",
            "Random samples for test + train entry 139 have been saved to '4_output_samples/random_samples_139.txt'\n",
            "Random samples for test + train entry 140 have been saved to '4_output_samples/random_samples_140.txt'\n",
            "Random samples for test + train entry 141 have been saved to '4_output_samples/random_samples_141.txt'\n",
            "Random samples for test + train entry 142 have been saved to '4_output_samples/random_samples_142.txt'\n",
            "Random samples for test + train entry 143 have been saved to '4_output_samples/random_samples_143.txt'\n",
            "Random samples for test + train entry 144 have been saved to '4_output_samples/random_samples_144.txt'\n",
            "Random samples for test + train entry 145 have been saved to '4_output_samples/random_samples_145.txt'\n",
            "Random samples for test + train entry 146 have been saved to '4_output_samples/random_samples_146.txt'\n",
            "Random samples for test + train entry 147 have been saved to '4_output_samples/random_samples_147.txt'\n",
            "Random samples for test + train entry 148 have been saved to '4_output_samples/random_samples_148.txt'\n",
            "Random samples for test + train entry 149 have been saved to '4_output_samples/random_samples_149.txt'\n",
            "Random samples for test + train entry 150 have been saved to '4_output_samples/random_samples_150.txt'\n",
            "Random samples have been saved to '4_output_samples'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Path to the folder you want to zip\n",
        "folder_to_zip = '/content/4_output_samples'\n",
        "# Name of the zip file\n",
        "zip_filename = '4_output_random_samples.zip'\n",
        "\n",
        "# Create a zip file\n",
        "shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', folder_to_zip)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_filename)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ZpoAR1TxfSV9",
        "outputId": "5259d483-4cce-4219-f19d-094027cd5c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cf18a103-c6ef-43b9-acd0-52c8d1cf9b05\", \"4_output_random_samples.zip\", 192134)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating each of 150 RANDOM txt entries**"
      ],
      "metadata": {
        "id": "v2G5HqeUfWG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_save_samples(input_dir, output_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for idx in range(150):\n",
        "        input_file = os.path.join(input_dir, f'random_samples_{idx+1}.txt')\n",
        "        output_file = os.path.join(output_dir, f'{idx+1}.txt')\n",
        "\n",
        "        with open(input_file, 'r', encoding='utf-8') as file:\n",
        "            data = [json.loads(line) for line in file]\n",
        "\n",
        "        dump_str = '''summarize the patient health query into one question of 15 words or less, using the provided examples to guide word choice \\n\\n'''\n",
        "        for entry_idx, entry in enumerate(data[1:]):\n",
        "            input_text = entry['data']['inputs'].strip().replace('\\n', '')\n",
        "            target = entry['data']['target'].strip().replace('\\n', '')\n",
        "            dump_str += f'query {entry_idx+1}: {input_text}\\n' + f'summarized question {entry_idx+1}: {target}\\n##\\n'\n",
        "\n",
        "        input_text = data[0]['data']['inputs']\n",
        "        dump_str += f'query {len(data)}: {input_text}\\n' + f'summarized question {len(data)}:'\n",
        "\n",
        "        with open(output_file, 'w', encoding='utf-8') as file:\n",
        "            file.write(dump_str)\n",
        "        print(f\"Processed and saved '{output_file}'\")"
      ],
      "metadata": {
        "id": "gmQCJJUSfWWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_samples_dir = '4_output_samples'\n",
        "final_output_dir = 'final_4_output_samples'\n",
        "if __name__ == \"__main__\":\n",
        "# Process and save the final output samples\n",
        "    process_and_save_samples(output_samples_dir, final_output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb-bL3LDfakI",
        "outputId": "6cb9a19d-2c22-436e-ae5a-4249a7a5738b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved 'final_4_output_samples/1.txt'\n",
            "Processed and saved 'final_4_output_samples/2.txt'\n",
            "Processed and saved 'final_4_output_samples/3.txt'\n",
            "Processed and saved 'final_4_output_samples/4.txt'\n",
            "Processed and saved 'final_4_output_samples/5.txt'\n",
            "Processed and saved 'final_4_output_samples/6.txt'\n",
            "Processed and saved 'final_4_output_samples/7.txt'\n",
            "Processed and saved 'final_4_output_samples/8.txt'\n",
            "Processed and saved 'final_4_output_samples/9.txt'\n",
            "Processed and saved 'final_4_output_samples/10.txt'\n",
            "Processed and saved 'final_4_output_samples/11.txt'\n",
            "Processed and saved 'final_4_output_samples/12.txt'\n",
            "Processed and saved 'final_4_output_samples/13.txt'\n",
            "Processed and saved 'final_4_output_samples/14.txt'\n",
            "Processed and saved 'final_4_output_samples/15.txt'\n",
            "Processed and saved 'final_4_output_samples/16.txt'\n",
            "Processed and saved 'final_4_output_samples/17.txt'\n",
            "Processed and saved 'final_4_output_samples/18.txt'\n",
            "Processed and saved 'final_4_output_samples/19.txt'\n",
            "Processed and saved 'final_4_output_samples/20.txt'\n",
            "Processed and saved 'final_4_output_samples/21.txt'\n",
            "Processed and saved 'final_4_output_samples/22.txt'\n",
            "Processed and saved 'final_4_output_samples/23.txt'\n",
            "Processed and saved 'final_4_output_samples/24.txt'\n",
            "Processed and saved 'final_4_output_samples/25.txt'\n",
            "Processed and saved 'final_4_output_samples/26.txt'\n",
            "Processed and saved 'final_4_output_samples/27.txt'\n",
            "Processed and saved 'final_4_output_samples/28.txt'\n",
            "Processed and saved 'final_4_output_samples/29.txt'\n",
            "Processed and saved 'final_4_output_samples/30.txt'\n",
            "Processed and saved 'final_4_output_samples/31.txt'\n",
            "Processed and saved 'final_4_output_samples/32.txt'\n",
            "Processed and saved 'final_4_output_samples/33.txt'\n",
            "Processed and saved 'final_4_output_samples/34.txt'\n",
            "Processed and saved 'final_4_output_samples/35.txt'\n",
            "Processed and saved 'final_4_output_samples/36.txt'\n",
            "Processed and saved 'final_4_output_samples/37.txt'\n",
            "Processed and saved 'final_4_output_samples/38.txt'\n",
            "Processed and saved 'final_4_output_samples/39.txt'\n",
            "Processed and saved 'final_4_output_samples/40.txt'\n",
            "Processed and saved 'final_4_output_samples/41.txt'\n",
            "Processed and saved 'final_4_output_samples/42.txt'\n",
            "Processed and saved 'final_4_output_samples/43.txt'\n",
            "Processed and saved 'final_4_output_samples/44.txt'\n",
            "Processed and saved 'final_4_output_samples/45.txt'\n",
            "Processed and saved 'final_4_output_samples/46.txt'\n",
            "Processed and saved 'final_4_output_samples/47.txt'\n",
            "Processed and saved 'final_4_output_samples/48.txt'\n",
            "Processed and saved 'final_4_output_samples/49.txt'\n",
            "Processed and saved 'final_4_output_samples/50.txt'\n",
            "Processed and saved 'final_4_output_samples/51.txt'\n",
            "Processed and saved 'final_4_output_samples/52.txt'\n",
            "Processed and saved 'final_4_output_samples/53.txt'\n",
            "Processed and saved 'final_4_output_samples/54.txt'\n",
            "Processed and saved 'final_4_output_samples/55.txt'\n",
            "Processed and saved 'final_4_output_samples/56.txt'\n",
            "Processed and saved 'final_4_output_samples/57.txt'\n",
            "Processed and saved 'final_4_output_samples/58.txt'\n",
            "Processed and saved 'final_4_output_samples/59.txt'\n",
            "Processed and saved 'final_4_output_samples/60.txt'\n",
            "Processed and saved 'final_4_output_samples/61.txt'\n",
            "Processed and saved 'final_4_output_samples/62.txt'\n",
            "Processed and saved 'final_4_output_samples/63.txt'\n",
            "Processed and saved 'final_4_output_samples/64.txt'\n",
            "Processed and saved 'final_4_output_samples/65.txt'\n",
            "Processed and saved 'final_4_output_samples/66.txt'\n",
            "Processed and saved 'final_4_output_samples/67.txt'\n",
            "Processed and saved 'final_4_output_samples/68.txt'\n",
            "Processed and saved 'final_4_output_samples/69.txt'\n",
            "Processed and saved 'final_4_output_samples/70.txt'\n",
            "Processed and saved 'final_4_output_samples/71.txt'\n",
            "Processed and saved 'final_4_output_samples/72.txt'\n",
            "Processed and saved 'final_4_output_samples/73.txt'\n",
            "Processed and saved 'final_4_output_samples/74.txt'\n",
            "Processed and saved 'final_4_output_samples/75.txt'\n",
            "Processed and saved 'final_4_output_samples/76.txt'\n",
            "Processed and saved 'final_4_output_samples/77.txt'\n",
            "Processed and saved 'final_4_output_samples/78.txt'\n",
            "Processed and saved 'final_4_output_samples/79.txt'\n",
            "Processed and saved 'final_4_output_samples/80.txt'\n",
            "Processed and saved 'final_4_output_samples/81.txt'\n",
            "Processed and saved 'final_4_output_samples/82.txt'\n",
            "Processed and saved 'final_4_output_samples/83.txt'\n",
            "Processed and saved 'final_4_output_samples/84.txt'\n",
            "Processed and saved 'final_4_output_samples/85.txt'\n",
            "Processed and saved 'final_4_output_samples/86.txt'\n",
            "Processed and saved 'final_4_output_samples/87.txt'\n",
            "Processed and saved 'final_4_output_samples/88.txt'\n",
            "Processed and saved 'final_4_output_samples/89.txt'\n",
            "Processed and saved 'final_4_output_samples/90.txt'\n",
            "Processed and saved 'final_4_output_samples/91.txt'\n",
            "Processed and saved 'final_4_output_samples/92.txt'\n",
            "Processed and saved 'final_4_output_samples/93.txt'\n",
            "Processed and saved 'final_4_output_samples/94.txt'\n",
            "Processed and saved 'final_4_output_samples/95.txt'\n",
            "Processed and saved 'final_4_output_samples/96.txt'\n",
            "Processed and saved 'final_4_output_samples/97.txt'\n",
            "Processed and saved 'final_4_output_samples/98.txt'\n",
            "Processed and saved 'final_4_output_samples/99.txt'\n",
            "Processed and saved 'final_4_output_samples/100.txt'\n",
            "Processed and saved 'final_4_output_samples/101.txt'\n",
            "Processed and saved 'final_4_output_samples/102.txt'\n",
            "Processed and saved 'final_4_output_samples/103.txt'\n",
            "Processed and saved 'final_4_output_samples/104.txt'\n",
            "Processed and saved 'final_4_output_samples/105.txt'\n",
            "Processed and saved 'final_4_output_samples/106.txt'\n",
            "Processed and saved 'final_4_output_samples/107.txt'\n",
            "Processed and saved 'final_4_output_samples/108.txt'\n",
            "Processed and saved 'final_4_output_samples/109.txt'\n",
            "Processed and saved 'final_4_output_samples/110.txt'\n",
            "Processed and saved 'final_4_output_samples/111.txt'\n",
            "Processed and saved 'final_4_output_samples/112.txt'\n",
            "Processed and saved 'final_4_output_samples/113.txt'\n",
            "Processed and saved 'final_4_output_samples/114.txt'\n",
            "Processed and saved 'final_4_output_samples/115.txt'\n",
            "Processed and saved 'final_4_output_samples/116.txt'\n",
            "Processed and saved 'final_4_output_samples/117.txt'\n",
            "Processed and saved 'final_4_output_samples/118.txt'\n",
            "Processed and saved 'final_4_output_samples/119.txt'\n",
            "Processed and saved 'final_4_output_samples/120.txt'\n",
            "Processed and saved 'final_4_output_samples/121.txt'\n",
            "Processed and saved 'final_4_output_samples/122.txt'\n",
            "Processed and saved 'final_4_output_samples/123.txt'\n",
            "Processed and saved 'final_4_output_samples/124.txt'\n",
            "Processed and saved 'final_4_output_samples/125.txt'\n",
            "Processed and saved 'final_4_output_samples/126.txt'\n",
            "Processed and saved 'final_4_output_samples/127.txt'\n",
            "Processed and saved 'final_4_output_samples/128.txt'\n",
            "Processed and saved 'final_4_output_samples/129.txt'\n",
            "Processed and saved 'final_4_output_samples/130.txt'\n",
            "Processed and saved 'final_4_output_samples/131.txt'\n",
            "Processed and saved 'final_4_output_samples/132.txt'\n",
            "Processed and saved 'final_4_output_samples/133.txt'\n",
            "Processed and saved 'final_4_output_samples/134.txt'\n",
            "Processed and saved 'final_4_output_samples/135.txt'\n",
            "Processed and saved 'final_4_output_samples/136.txt'\n",
            "Processed and saved 'final_4_output_samples/137.txt'\n",
            "Processed and saved 'final_4_output_samples/138.txt'\n",
            "Processed and saved 'final_4_output_samples/139.txt'\n",
            "Processed and saved 'final_4_output_samples/140.txt'\n",
            "Processed and saved 'final_4_output_samples/141.txt'\n",
            "Processed and saved 'final_4_output_samples/142.txt'\n",
            "Processed and saved 'final_4_output_samples/143.txt'\n",
            "Processed and saved 'final_4_output_samples/144.txt'\n",
            "Processed and saved 'final_4_output_samples/145.txt'\n",
            "Processed and saved 'final_4_output_samples/146.txt'\n",
            "Processed and saved 'final_4_output_samples/147.txt'\n",
            "Processed and saved 'final_4_output_samples/148.txt'\n",
            "Processed and saved 'final_4_output_samples/149.txt'\n",
            "Processed and saved 'final_4_output_samples/150.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Path to the folder you want to zip\n",
        "folder_to_zip = '/content/final_4_output_samples'\n",
        "# Name of the zip file\n",
        "zip_filename = 'final_4_each_random_samples.zip'\n",
        "\n",
        "# Create a zip file\n",
        "shutil.make_archive(zip_filename.replace('.zip', ''), 'zip', folder_to_zip)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dfLdlul_fd3S",
        "outputId": "f4e93379-3140-41a6-a05a-8b43d7f282ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_121f260d-3f6f-4bd3-bd3d-b1e51a2323d3\", \"final_4_each_random_samples.zip\", 185698)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfo_vf9NgsGN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}