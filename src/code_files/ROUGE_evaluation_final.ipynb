{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge-score in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from rouge-score) (1.24.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: click in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from nltk->rouge-score) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from nltk->rouge-score) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\shama\\anaconda3\\envs\\clin-summ\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rouge-score pandas\n",
    "from rouge_score import rouge_scorer,scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "\n",
    "# Function to calculate ROUGE scores\n",
    "def calculate_rouge(hypotheses, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    aggregator = scoring.BootstrapAggregator()\n",
    "\n",
    "    for hyp, ref in zip(hypotheses, references):\n",
    "        scores = scorer.score(ref, hyp)\n",
    "        aggregator.add_scores(scores)\n",
    "\n",
    "    result = aggregator.aggregate()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of Reference Summaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total targets extracted: 150\n",
      "Example targets: ['How can i get rid of a lower lip birthmark permanently?', 'Is Magnesium Silicofluoride safe for people?', 'Could RhoGAM damage the baby?', 'Could hydroxychloroquine and methotrexate make me sweat? ', 'Is there a relationship between Gadolinium and Multiple Chemical Sensitivity?']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "#Directory containing our JSONL format text files\n",
    "folder_name = '/data/chq/generated_files'\n",
    "next_folder_name = '1_output_similar_samples'\n",
    "\n",
    "# Join the folder and file names to create a full path\n",
    "directory = os.path.join(folder_name, next_folder_name)\n",
    "\n",
    "\n",
    "# List to store all targets\n",
    "all_targets = []\n",
    "\n",
    "# Find all files in the directory that match the pattern 'similar_samples_<number>.txt'\n",
    "file_list = [filename for filename in os.listdir(directory) if filename.startswith('similar_samples_') and filename.endswith('.txt')]\n",
    "\n",
    "# Sort the file list based on the numeric part\n",
    "file_list.sort(key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
    "\n",
    "# Iterate through each file in the sorted list\n",
    "for filename in file_list:\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    # Open the file and read line by line\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Parse each line as JSON\n",
    "            json_obj = json.loads(line)\n",
    "            \n",
    "            # Check if the object is of type 'TEST_ENTRY'\n",
    "            if json_obj[\"type\"] == \"TEST_ENTRY\":\n",
    "                # Extract the 'target' part\n",
    "                target_text = json_obj[\"data\"][\"target\"]\n",
    "                # Append to the list of all targets\n",
    "                all_targets.append(target_text)\n",
    "\n",
    "# Print or use `all_targets` as needed\n",
    "print(\"Total targets extracted:\", len(all_targets))\n",
    "print(\"Example targets:\", all_targets[:5])  # Print first 5 targets as an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summaries = all_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_SIMILAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing Generated Summaries\n",
    "folder_name = '/data/chq/generated_files/Generated_Summaries_SIMILAR'\n",
    "file_name = 'LLaMa2_7b_1_Similar_final.txt'\n",
    "\n",
    "# Join the folder and file names to create a full path\n",
    "generated_file_path = os.path.join(folder_name, file_name)\n",
    "generated_summaries = []\n",
    "\n",
    "# Read the file and extract summaries from lines divisible by 4 (0-based index)\n",
    "with open(generated_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines), 4):\n",
    "        generated_summary = lines[i].strip()  # Assuming summary is in the first line of each group\n",
    "        generated_summaries.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global ROUGE scores:\n",
      "ROUGE-1: 0.31590832694355175\n",
      "ROUGE-2: 0.1411967059968725\n",
      "ROUGE-L: 0.29306829497677234\n"
     ]
    }
   ],
   "source": [
    "global_rouge_scores = calculate_rouge(generated_summaries, reference_summaries)\n",
    "print(\"Global ROUGE scores:\")\n",
    "# print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")\n",
    "\n",
    "print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2_SIMILAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing Generated Summaries\n",
    "folder_name = '/data/chq/generated_files/Generated_Summaries_SIMILAR'\n",
    "file_name = 'LLaMa2_7b_2_Similar_final.txt'\n",
    "\n",
    "# Join the folder and file names to create a full path\n",
    "generated_file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "generated_summaries = []\n",
    "\n",
    "# Read the file and extract summaries from lines divisible by 4 (0-based index)\n",
    "with open(generated_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines), 4):\n",
    "        generated_summary = lines[i].strip()  # Assuming summary is in the first line of each group\n",
    "        generated_summaries.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global ROUGE scores:\n",
      "ROUGE-1: 0.3373758996635882\n",
      "ROUGE-2: 0.14737605318558622\n",
      "ROUGE-L: 0.31484046346457184\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global_rouge_scores = calculate_rouge(generated_summaries, reference_summaries)\n",
    "print(\"Global ROUGE scores:\")\n",
    "# print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")\n",
    "\n",
    "print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4_SIMILAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing Generated Summaries\n",
    "folder_name = '/data/chq/generated_files/Generated_Summaries_SIMILAR'\n",
    "file_name = 'LLaMa2_7b_4_Similar_final.txt'\n",
    "\n",
    "# Join the folder and file names to create a full path\n",
    "generated_file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "generated_summaries = []\n",
    "\n",
    "# Read the file and extract summaries from lines divisible by 4 (0-based index)\n",
    "with open(generated_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines), 4):\n",
    "        generated_summary = lines[i].strip()  # Assuming summary is in the first line of each group\n",
    "        generated_summaries.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global ROUGE scores:\n",
      "ROUGE-1: 0.32515292707724286\n",
      "ROUGE-2: 0.13277004760570627\n",
      "ROUGE-L: 0.30461507515250547\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global_rouge_scores = calculate_rouge(generated_summaries, reference_summaries)\n",
    "print(\"Global ROUGE scores:\")\n",
    "# print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")\n",
    "\n",
    "print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8_SIMILAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing Generated Summaries\n",
    "folder_name = '/data/chq/generated_files/Generated_Summaries_SIMILAR'\n",
    "file_name = 'LLaMa2_7b_8_Similar_final.txt'\n",
    "\n",
    "# Join the folder and file names to create a full path\n",
    "generated_file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "generated_summaries = []\n",
    "\n",
    "# Read the file and extract summaries from lines divisible by 4 (0-based index)\n",
    "with open(generated_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines), 4):\n",
    "        generated_summary = lines[i].strip()  # Assuming summary is in the first line of each group\n",
    "        generated_summaries.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global ROUGE scores:\n",
      "ROUGE-1: 0.32895431007758635\n",
      "ROUGE-2: 0.13548752546613907\n",
      "ROUGE-L: 0.3042740321035373\n"
     ]
    }
   ],
   "source": [
    "global_rouge_scores = calculate_rouge(generated_summaries, reference_summaries)\n",
    "print(\"Global ROUGE scores:\")\n",
    "# print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")\n",
    "\n",
    "print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16_SIMILAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing Generated Summaries\n",
    "folder_name = '/data/chq/generated_files/Generated_Summaries_SIMILAR'\n",
    "file_name = 'LLaMa2_7b_16_Similar_final.txt'\n",
    "\n",
    "# Join the folder and file names to create a full path\n",
    "generated_file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "generated_summaries = []\n",
    "\n",
    "# Read the file and extract summaries from lines divisible by 4 (0-based index)\n",
    "with open(generated_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines), 4):\n",
    "        generated_summary = lines[i].strip()  # Assuming summary is in the first line of each group\n",
    "        generated_summaries.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global ROUGE scores:\n",
      "ROUGE-1: 0.3406772230483699\n",
      "ROUGE-2: 0.14940301342284282\n",
      "ROUGE-L: 0.31753571741501485\n"
     ]
    }
   ],
   "source": [
    "global_rouge_scores = calculate_rouge(generated_summaries, reference_summaries)\n",
    "print(\"Global ROUGE scores:\")\n",
    "# print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")\n",
    "\n",
    "print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_RANDOM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing Generated Summaries\n",
    "folder_name = '/data/chq/generated_files/Generated_Summaries_RANDOM'\n",
    "file_name = 'LLaMa2_7b_1_Random_final.txt'\n",
    "\n",
    "# Join the folder and file names to create a full path\n",
    "generated_file_path = os.path.join(folder_name, file_name)\n",
    "generated_summaries = []\n",
    "\n",
    "# Read the file and extract summaries from lines divisible by 4 (0-based index)\n",
    "with open(generated_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines), 4):\n",
    "        generated_summary = lines[i].strip()  # Assuming summary is in the first line of each group\n",
    "        generated_summaries.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global ROUGE scores:\n",
      "ROUGE-1: 0.3069791397609623\n",
      "ROUGE-2: 0.12128170373590882\n",
      "ROUGE-L: 0.28361862759233747\n"
     ]
    }
   ],
   "source": [
    "global_rouge_scores = calculate_rouge(generated_summaries, reference_summaries)\n",
    "print(\"Global ROUGE scores:\")\n",
    "# print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")\n",
    "\n",
    "print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2_RANDOM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing Generated Summaries\n",
    "folder_name = '/data/chq/generated_files/Generated_Summaries_RANDOM'\n",
    "file_name = 'LLaMa2_7b_2_Random_final.txt'\n",
    "\n",
    "# Join the folder and file names to create a full path\n",
    "generated_file_path = os.path.join(folder_name, file_name)\n",
    "generated_summaries = []\n",
    "\n",
    "# Read the file and extract summaries from lines divisible by 4 (0-based index)\n",
    "with open(generated_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines), 4):\n",
    "        generated_summary = lines[i].strip()  # Assuming summary is in the first line of each group\n",
    "        generated_summaries.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global ROUGE scores:\n",
      "ROUGE-1: 0.3281040416483221\n",
      "ROUGE-2: 0.14294825798092742\n",
      "ROUGE-L: 0.3094953509057816\n"
     ]
    }
   ],
   "source": [
    "global_rouge_scores = calculate_rouge(generated_summaries, reference_summaries)\n",
    "print(\"Global ROUGE scores:\")\n",
    "# print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")\n",
    "\n",
    "print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4_RANDOM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing Generated Summaries\n",
    "folder_name = '/data/chq/generated_files/Generated_Summaries_RANDOM'\n",
    "file_name = 'LLaMa2_7b_4_Random_final.txt'\n",
    "\n",
    "# Join the folder and file names to create a full path\n",
    "generated_file_path = os.path.join(folder_name, file_name)\n",
    "generated_summaries = []\n",
    "\n",
    "# Read the file and extract summaries from lines divisible by 4 (0-based index)\n",
    "with open(generated_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines), 4):\n",
    "        generated_summary = lines[i].strip()  # Assuming summary is in the first line of each group\n",
    "        generated_summaries.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global ROUGE scores:\n",
      "ROUGE-1: 0.33759138139606604\n",
      "ROUGE-2: 0.14070252198695163\n",
      "ROUGE-L: 0.3194696836117361\n"
     ]
    }
   ],
   "source": [
    "global_rouge_scores = calculate_rouge(generated_summaries, reference_summaries)\n",
    "print(\"Global ROUGE scores:\")\n",
    "# print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")\n",
    "\n",
    "print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8_RANDOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing Generated Summaries\n",
    "folder_name = '/data/chq/generated_files/Generated_Summaries_RANDOM'\n",
    "file_name = 'LLaMa2_7b_8_Random_final.txt'\n",
    "\n",
    "# Join the folder and file names to create a full path\n",
    "generated_file_path = os.path.join(folder_name, file_name)\n",
    "generated_summaries = []\n",
    "\n",
    "# Read the file and extract summaries from lines divisible by 4 (0-based index)\n",
    "with open(generated_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines), 4):\n",
    "        generated_summary = lines[i].strip()  # Assuming summary is in the first line of each group\n",
    "        generated_summaries.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global ROUGE scores:\n",
      "ROUGE-1: 0.3274355054857176\n",
      "ROUGE-2: 0.14836898402712356\n",
      "ROUGE-L: 0.3126347303380933\n"
     ]
    }
   ],
   "source": [
    "global_rouge_scores = calculate_rouge(generated_summaries, reference_summaries)\n",
    "print(\"Global ROUGE scores:\")\n",
    "# print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")\n",
    "\n",
    "print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16_RANDOM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File containing Generated Summaries\n",
    "folder_name = '/data/chq/generated_files/Generated_Summaries_RANDOM'\n",
    "file_name = 'LLaMa2_7b_16_Random_final.txt'\n",
    "\n",
    "# Join the folder and file names to create a full path\n",
    "generated_file_path = os.path.join(folder_name, file_name)\n",
    "generated_summaries = []\n",
    "\n",
    "# Read the file and extract summaries from lines divisible by 4 (0-based index)\n",
    "with open(generated_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(0, len(lines), 4):\n",
    "        generated_summary = lines[i].strip()  # Assuming summary is in the first line of each group\n",
    "        generated_summaries.append(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global ROUGE scores:\n",
      "ROUGE-1: 0.33581722522731106\n",
      "ROUGE-2: 0.1614674826689948\n",
      "ROUGE-L: 0.322289520553383\n"
     ]
    }
   ],
   "source": [
    "global_rouge_scores = calculate_rouge(generated_summaries, reference_summaries)\n",
    "print(\"Global ROUGE scores:\")\n",
    "# print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "# print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")\n",
    "\n",
    "print(f\"ROUGE-1: {global_rouge_scores['rouge1'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-2: {global_rouge_scores['rouge2'].mid.fmeasure}\")\n",
    "print(f\"ROUGE-L: {global_rouge_scores['rougeL'].mid.fmeasure}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
